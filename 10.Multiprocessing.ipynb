{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pierre Navaro - [Institut de Recherche Mathématique de Rennes](https://irmar.univ-rennes1.fr) - [CNRS](http://www.cnrs.fr/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* [multiprocessing basics](https://pymotw.com/2/multiprocessing/basics.html)\n",
    "* [Python 201: A multiprocessing tutorial](https://www.blog.pythonlibrary.org/2016/08/02/python-201-a-multiprocessing-tutorial/)\n",
    "* [Multithread - Konrad Hinsen](http://calcul.math.cnrs.fr/Documents/Ecoles/2013/python/Multiprocessing.pdf)\n",
    "* [Parallel Data Analysis in Python | SciPy 2017 Tutorial | Matthew Rocklin, Ben Zaitlen & Aron Ahmadia](https://youtu.be/a8gpcnmggiU)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Multiprocessing\n",
    "\n",
    "- The multiprocessing allows the programmer to fully leverage multiple processors. \n",
    "- It runs on both Unix and Windows.\n",
    "- The `Pool` object parallelizes the execution of a function across multiple input values.\n",
    "- The if `__name__ == '__main__'` part is necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 5, 10, 17, 26, 37, 50]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def f(x): return x*x+1  # Function executed on worker processes.\n",
    "\n",
    "if __name__ == '__main__': # Executed only on main process.\n",
    "    with Pool(4) as p:\n",
    "        print(p.map(f, list(range(8))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 4, 6, 8, 10, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "def g(x, y): return x+y  # Function executed on worker processes.\n",
    "\n",
    "if __name__ == '__main__': # Executed only on main process.\n",
    "    with Pool(4) as p:\n",
    "        print(p.starmap(g, \n",
    "            ((x,y) for x,y in zip(list(range(8)),list(range(8))))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Asynchronous Apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 1.0, 1.4142135623730951, 1.7320508075688772, 2.0, 2.2360679774997898, 2.4494897427831779, 2.6457513110645907, 2.8284271247461903, 3.0]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Pool\n",
    "import numpy\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pool = Pool()\n",
    "    results = [pool.apply_async(numpy.sqrt, (x,))\n",
    "               for x in range(10)]\n",
    "    roots = [r.get() for r in results]\n",
    "    print(roots)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use for:\n",
    "- `pool.apply_async` returns a proxy object immediately\n",
    "- `proxy.get()` waits for task completion and returns the result\n",
    "- launching different tasks in parallel\n",
    "- launching tasks with more than one argument \n",
    "- better control of task distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# The Process class\n",
    "\n",
    "In multiprocessing, processes are spawned by creating a Process object and then calling its start() method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello bob\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process\n",
    "\n",
    "def f(name):\n",
    "    print('hello', name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    p = Process(target=f, args=('bob',))\n",
    "    p.start()\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Exchanging objects between processes\n",
    "\n",
    "## Queues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(q):\n",
    "    q.put([42, None, 'hello'])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    q = Queue()\n",
    "    p = Process(target=f, args=(q,))\n",
    "    p.start()\n",
    "    print(q.get())    # prints \"[42, None, 'hello']\"\n",
    "    p.join()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Pipes\n",
    "Pipe() returns two connection objects. Each connection object has send() and recv() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42, None, 'hello']\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Pipe\n",
    "\n",
    "def f(conn):\n",
    "    conn.send([42, None, 'hello'])\n",
    "    conn.close()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parent_conn, child_conn = Pipe()\n",
    "    p = Process(target=f, args=(child_conn,))\n",
    "    p.start()\n",
    "    print(parent_conn.recv())   # prints \"[42, None, 'hello']\"\n",
    "    p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Synchronization between processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Lock\n",
    "\n",
    "def f(l, i):\n",
    "    l.acquire()\n",
    "    try:\n",
    "        print( i, end = ' ')\n",
    "    finally:\n",
    "        l.release()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lock = Lock()\n",
    "\n",
    "    for num in range(10):\n",
    "        Process(target=f, args=(lock, num)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1 2 3 4 5 6 7 8 9 "
     ]
    }
   ],
   "source": [
    "def f( i):\n",
    "    print( i, end = ' ')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    for num in range(10):\n",
    "        Process(target=f, args=(num,)).start()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Shared memory between processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1415927\n",
      "[0, -1, -2, -3, -4, -5, -6, -7, -8, -9]\n"
     ]
    }
   ],
   "source": [
    "from multiprocessing import Process, Value, Array\n",
    "\n",
    "def f(n, a):\n",
    "    n.value = 3.1415927\n",
    "    for i in range(len(a)):\n",
    "        a[i] = -a[i]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    num = Value('d', 0.0)\n",
    "    arr = Array('i', range(10))\n",
    "\n",
    "    p = Process(target=f, args=(num, arr))\n",
    "    p.start()\n",
    "    p.join()\n",
    "\n",
    "    print(num.value)\n",
    "    print(arr[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Shared memory eliminates the serialization overhead.\n",
    "- Don’t modify shared memory contents in the slave processes. \n",
    "- Use shared memory only to transfer data from the master to the slaves!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cores 1, Estimated value of Pi : 3.14138240 time : 3.17626691\n",
      "Number of cores 2, Estimated value of Pi : 3.14219680 time : 1.62062216\n",
      "Number of cores 3, Estimated value of Pi : 3.14137800 time : 1.09223890\n",
      "Number of cores 4, Estimated value of Pi : 3.14048640 time : 0.84245205\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "from multiprocessing import Pool, cpu_count\n",
    "\n",
    "def compute_pi(n):\n",
    "    count = 0\n",
    "    for i in range(n):\n",
    "        x=random.random()\n",
    "        y=random.random()\n",
    "        if x*x + y*y <= 1: count+=1\n",
    "    return count\n",
    "\n",
    "if __name__=='__main__':\n",
    "    \n",
    "    for np in range(1,5):\n",
    "        elapsed_time = time.time()\n",
    "        assert ( np <= cpu_count())\n",
    "        \n",
    "        n = 10000000\n",
    "        part_count=[n//np for i in range(np)]\n",
    "        pool = Pool(processes=np)   \n",
    "        count=pool.map(compute_pi, part_count)\n",
    "        print (\"Number of cores {0}, Estimated value of Pi : {1:.8f}\"\n",
    "       \" time : {2:.8f}\".format(np, 4*sum(count)/n,time.time()-elapsed_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Joblib\n",
    "\n",
    "[Joblib](http://pythonhosted.org/joblib/) provides a simple helper class to write parallel for loops using multiprocessing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    return x*x\n",
    "\n",
    "[f(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 4, 9, 16, 25, 36, 49, 64, 81]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "Parallel(n_jobs=2)(delayed(f)(x) for x in range(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercice\n",
    "\n",
    "Write the program in which two processes send packets of information back and forth a 100 times and record the amount of time required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 doubled to 10 by: Process-2\n",
      "10 doubled to 20 by: Process-3\n",
      "15 doubled to 30 by: Process-4\n",
      "20 doubled to 40 by: Process-5\n",
      "25 doubled to 50 by: Process-6\n",
      "2 doubled to 4 by: Test\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    " \n",
    "from multiprocessing import Process, current_process\n",
    " \n",
    " \n",
    "def doubler(number):\n",
    "    \"\"\"\n",
    "    A doubling function that can be used by a process\n",
    "    \"\"\"\n",
    "    result = number * 2\n",
    "    proc_name = current_process().name\n",
    "    print('{0} doubled to {1} by: {2}'.format(\n",
    "        number, result, proc_name))\n",
    " \n",
    " \n",
    "if __name__ == '__main__':\n",
    "    numbers = [5, 10, 15, 20, 25]\n",
    "    procs = []\n",
    "    proc = Process(target=doubler, args=(5,))\n",
    " \n",
    "    for index, number in enumerate(numbers):\n",
    "        proc = Process(target=doubler, args=(number,))\n",
    "        procs.append(proc)\n",
    "        proc.start()\n",
    " \n",
    "    proc = Process(target=doubler, name='Test', args=(2,))\n",
    "    proc.start()\n",
    "    procs.append(proc)\n",
    " \n",
    "    for proc in procs:\n",
    "        proc.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sharedmem\n",
    "\n",
    "http://rainwoodman.github.io/sharedmem/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 45.]\n"
     ]
    }
   ],
   "source": [
    "import sharedmem\n",
    "counter = sharedmem.empty(1)\n",
    "counter[:] = 0\n",
    "with sharedmem.MapReduce() as pool:\n",
    "    def work(i):\n",
    "         with pool.critical:\n",
    "             counter[:] += i\n",
    "    pool.map(work, range(10))\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chunk 0 done\n",
      "chunk 1048576 done\n",
      "chunk 2097152 done\n",
      "chunk 3145728 done\n",
      "chunk 4194304 done\n",
      "chunk 5242880 done\n",
      "chunk 6291456 done\n",
      "chunk 7340032 done\n",
      "chunk 8388608 done\n",
      "chunk 9437184 done\n",
      "chunk 10485760 done\n",
      "chunk 11534336 done\n",
      "chunk 12582912 done\n",
      "chunk 13631488 done\n",
      "chunk 14680064 done\n",
      "chunk 15728640 done\n",
      "chunk 16777216 done\n",
      "chunk 17825792 done\n",
      "chunk 18874368 done\n",
      "chunk 19922944 done\n",
      "chunk 24117248 done\n",
      "chunk 20971520 done\n",
      "chunk 22020096 done\n",
      "chunk 23068672 done\n",
      "chunk 25165824 done\n",
      "chunk 26214400 done\n",
      "chunk 27262976 done\n",
      "chunk 29360128 done\n",
      "chunk 28311552 done\n",
      "chunk 33554432 done\n",
      "chunk 30408704 done\n",
      "chunk 31457280 done\n",
      "chunk 32505856 done\n",
      "chunk 34603008 done\n",
      "chunk 36700160 done\n",
      "chunk 35651584 done\n",
      "chunk 37748736 done\n",
      "chunk 39845888 done\n",
      "chunk 38797312 done\n",
      "chunk 40894464 done\n",
      "chunk 41943040 done\n",
      "chunk 42991616 done\n",
      "chunk 44040192 done\n",
      "chunk 50331648 done\n",
      "chunk 45088768 done\n",
      "chunk 46137344 done\n",
      "chunk 47185920 done\n",
      "chunk 49283072 done\n",
      "chunk 48234496 done\n",
      "chunk 51380224 done\n",
      "chunk 52428800 done\n",
      "chunk 53477376 done\n",
      "chunk 54525952 done\n",
      "chunk 55574528 done\n",
      "chunk 57671680 done\n",
      "chunk 58720256 done\n",
      "chunk 56623104 done\n",
      "chunk 59768832 done\n",
      "chunk 60817408 done\n",
      "chunk 61865984 done\n",
      "chunk 62914560 done\n",
      "chunk 67108864 done\n",
      "chunk 63963136 done\n",
      "chunk 68157440 done\n",
      "chunk 65011712 done\n",
      "chunk 66060288 done\n",
      "chunk 69206016 done\n",
      "chunk 71303168 done\n",
      "chunk 70254592 done\n",
      "chunk 73400320 done\n",
      "chunk 72351744 done\n",
      "chunk 74448896 done\n",
      "chunk 75497472 done\n",
      "chunk 76546048 done\n",
      "chunk 77594624 done\n",
      "chunk 80740352 done\n",
      "chunk 82837504 done\n",
      "chunk 78643200 done\n",
      "chunk 83886080 done\n",
      "chunk 84934656 done\n",
      "chunk 81788928 done\n",
      "chunk 85983232 done\n",
      "chunk 79691776 done\n",
      "chunk 88080384 done\n",
      "chunk 87031808 done\n",
      "chunk 89128960 done\n",
      "chunk 90177536 done\n",
      "chunk 91226112 done\n",
      "chunk 92274688 done\n",
      "chunk 93323264 done\n",
      "chunk 94371840 done\n",
      "chunk 100663296 done\n",
      "chunk 101711872 done\n",
      "chunk 102760448 done\n",
      "chunk 96468992 done\n",
      "chunk 97517568 done\n",
      "chunk 95420416 done\n",
      "chunk 99614720 done\n",
      "chunk 98566144 done\n",
      "chunk 103809024 done\n",
      "chunk 105906176 done\n",
      "chunk 104857600 done\n",
      "chunk 106954752 done\n",
      "chunk 108003328 done\n",
      "chunk 110100480 done\n",
      "chunk 109051904 done\n",
      "chunk 111149056 done\n",
      "chunk 112197632 done\n",
      "chunk 118489088 done\n",
      "chunk 117440512 done\n",
      "chunk 119537664 done\n",
      "chunk 113246208 done\n",
      "chunk 114294784 done\n",
      "chunk 115343360 done\n",
      "chunk 116391936 done\n",
      "chunk 120586240 done\n",
      "chunk 121634816 done\n",
      "chunk 123731968 done\n",
      "chunk 122683392 done\n",
      "chunk 125829120 done\n",
      "chunk 124780544 done\n",
      "chunk 126877696 done\n",
      "chunk 127926272 done\n",
      "chunk 128974848 done\n",
      "chunk 131072000 done\n",
      "chunk 130023424 done\n",
      "chunk 132120576 done\n",
      "chunk 133169152 done\n",
      "9.00719918763e+15\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "input = np.arange(1024 * 1024 * 128, dtype='f8')\n",
    "output = sharedmem.empty(1024 * 1024 * 128, dtype='f8')\n",
    "with sharedmem.MapReduce() as pool:\n",
    "    chunksize = 1024 * 1024\n",
    "    def work(i):\n",
    "        s = slice (i, i + chunksize)\n",
    "        output[s] = input[s]\n",
    "        return i, np.sum(input[s])\n",
    "    def reduce(i, r):\n",
    "        print('chunk', i, 'done')\n",
    "        return r\n",
    "    r = pool.map(work, range(0, len(input), chunksize), reduce=reduce)\n",
    "print (np.sum(r))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Futures\n",
    "\n",
    "The concurrent.futures module provides a high-level interface for asynchronously executing callables.\n",
    "\n",
    "The asynchronous execution can be performed with threads, using ThreadPoolExecutor, or separate processes, using ProcessPoolExecutor. Both implement the same interface, which is defined by the abstract Executor class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.11 ms, sys: 1.17 ms, total: 2.28 ms\n",
      "Wall time: 8.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import time\n",
    "results = []\n",
    "for i in range(8):\n",
    "    time.sleep(1)\n",
    "    results.append(i + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.8 ms, sys: 25.7 ms, total: 39.5 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "e = ProcessPoolExecutor()\n",
    "def slowinc(x):\n",
    "    time.sleep(1)\n",
    "    return x + 1\n",
    "results = list(e.map(slowinc, range(8)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Today most library designers are coordinating around the concurrent.futures interface, so it's wise to move over.\n",
    "\n",
    "* Used snakeviz to profile code\n",
    "* Used concurrent.futures.ProcessPoolExecutor for simple parallelism \n",
    "* Gained some speed boost (but not as much as expected)\n",
    "* Lost ability to diagnose performance within parallel code\n",
    "* Describing each task as a function call helps use tools like map for parallelism\n",
    "* Making your tasks fast is often at least as important as parallelizing your tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Asynchronous Future\n",
    "While many parallel applications can be described as maps, some can be more complex. In this section we look at the asynchronous Future interface, which provides a simple API for ad-hoc parallelism. This is useful for when your computations don't fit a regular pattern.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Executor.submit\n",
    "\n",
    "The `submit` method starts a computation in a separate thread or process and immediately gives us a `Future` object that refers to the result.  At first, the future is pending.  Once the function completes the future is finished. \n",
    "\n",
    "We collect the result of the task with the `.result()` method,\n",
    "which does not return until the results are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def slowadd(a, b, delay=1):\n",
    "    sleep(delay)\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Future at 0x111f54e80 state=running>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "e = ThreadPoolExecutor(4)\n",
    "future = e.submit(slowadd, 1, 2)\n",
    "future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "future.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Submit many tasks all at once and they will execute in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.4 ms, sys: 25.6 ms, total: 48 ms\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "results = [slowadd(i, i, delay=1) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.95 ms, sys: 9.59 ms, total: 18.5 ms\n",
      "Wall time: 3.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "futures = [e.submit(slowadd, 1, 1, delay=1) for i in range(10)]\n",
    "results = [f.result() for f in futures]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "*  Submit fires off a single function call in the background, returning a future.  \n",
    "*  When you combine submit with a single for loop we recover the functionality of map.  \n",
    "*  To collect your results, replace each of futures, `f`, with a call to `f.result()`\n",
    "*  Combine submit with multiple for loops and other general programming to get something more general than map.\n",
    "*  Sometimes, it did not speed up the code very much\n",
    "*  Threads and processes show some performance differences\n",
    "*  Use threads carefully, you can break your Python session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
